<div align="center">

<br/>

```
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘          âœ‹  CV GESTURE SYSTEM ULTRA  v3                  â•‘
â•‘     Air Writing Â· 13 Shapes Â· Custom Gestures Â· Zero-Lag â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

<img src="https://img.shields.io/badge/MediaPipe-Hands-00c8ff?style=for-the-badge&logo=google&logoColor=white"/>
<img src="https://img.shields.io/badge/Platform-Google%20Colab-F9AB00?style=for-the-badge&logo=googlecolab&logoColor=white"/>
<img src="https://img.shields.io/badge/JavaScript-Vanilla-7c3aed?style=for-the-badge&logo=javascript&logoColor=white"/>
<img src="https://img.shields.io/badge/No%20Install-Zero%20Dependencies-00ff88?style=for-the-badge"/>

<br/><br/>

**A real-time, browser-based computer vision canvas controlled entirely by hand gestures.**
Draw in the air, stamp emojis, lock geometric shapes, and undo strokes â€” no mouse, no touch, no setup required.

<br/>

</div>

---

## âœ¨ Feature Highlights

| Feature | Details |
|---|---|
| ğŸ¤š **9 Built-in Gestures** | Pointing, Fist, Peace, Thumbs Up/Down, Rock On, OK, Open Hand, Both Fists |
| ğŸ”· **13 Geometric Shapes** | Circle, Ellipse, Rectangle, Square, Triangle, Diamond, Star (5/6-pt), Pentagon, Hexagon, Cross, Arrow, Double Arrow |
| ğŸ–Œï¸ **4 Brush Styles** | Round, Square, Glow, Neon â€” with adjustable size & 8-color palette |
| ğŸ¨ **Stamp Mode** | 12 emoji stamps (â­â¤ï¸ğŸ”¥ğŸ’ğŸ¯âš¡ğŸŒˆğŸš€ğŸ’€ğŸ‘‘ğŸŒ¸âœ…) with adjustable size |
| â†©ï¸ **Undo / Redo** | 20-level history stack via Rock On gesture or `Ctrl+Z` |
| âœŠâœŠ **Fist-to-Lock** | Hold both fists 1.5s to permanently lock any shape onto the canvas |
| â• **Custom Gestures** | Capture your own hand poses and bind them to actions |
| ğŸ’¾ **Canvas Export** | Preview + download composite drawing as PNG |
| âš¡ **Zero-Lag Pipeline** | MediaPipe Hands runs in-browser via CDN â€” no Python inference bottleneck |
| ğŸ“± **Responsive UI** | Adapts to desktop and mobile layouts automatically |

---

## ğŸ¬ How It Works

```
webcam feed
    â”‚
    â–¼
MediaPipe Hands (browser CDN)
    â”‚  21 landmarks per hand @ 30fps
    â–¼
Gesture Classifier (JS)
    â”‚  Pointing / Fist / Peace / OK / ThumbsUp ...
    â–¼
Action Dispatcher
    â”‚
    â”œâ”€â”€â–º Draw Mode  â†’ brush strokes on <canvas>
    â”œâ”€â”€â–º Erase Mode â†’ circular eraser at fingertip
    â”œâ”€â”€â–º Stamp Mode â†’ emoji placed at index tip
    â””â”€â”€â–º Shape Mode â†’ ghost preview + FistÃ—2 to commit
```

The app runs entirely inside a single HTML page served through a lightweight Python HTTP server embedded in the Colab notebook â€” no external backend, no WebSocket, no cloud inference.

---

## ğŸš€ Quick Start

> **Requirements:** A Google account and a webcam. That's it.

**1. Open the notebook in Google Colab**

```
File â†’ Open Notebook â†’ Upload â†’ CV_GESTURE_SYSTEM.ipynb
```

Or click:

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/)

**2. Run Cell 1**

```python
# CELL 1 â€” No pip installs needed! MediaPipe runs in browser via CDN
print('âœ… Ready! Run Cell 2 to launch the zero-lag interface.')
```

**3. Run Cell 2**

A local HTTP server starts on port `8765`. A Colab tunnel URL is printed and opened automatically.

**4. Allow camera access** in the new browser tab, then click **â–¶ START**.

---

## ğŸ¤š Gesture Reference

| Gesture | Action |
|---|---|
| â˜ï¸ **Index Finger (Pointing)** | Draw / Stamp / Erase depending on active mode tab |
| âœŠ **Fist** | Lift pen â€” pauses drawing without switching mode |
| âœŠâœŠ **Both Fists** | Hold 1.5 seconds â†’ lock current shape permanently onto canvas |
| ğŸ‘ **Thumbs Up** | Instant eraser at thumb tip |
| ğŸ‘ **Thumbs Down** | Cycle draw color through the palette |
| ğŸ‘Œ **OK Sign** | Stamp a glowing circle at the hand position |
| âœŒï¸ **Peace** | Shape resize (use two hands to scale) |
| ğŸ¤˜ **Rock On** | Undo last stroke |
| ğŸ– **Open Hand** | Pause / freeze current tool |

### Keyboard Shortcuts

| Key | Action |
|---|---|
| `Ctrl + Z` | Undo |
| `Space` | Clear canvas |
| `1` | Draw mode |
| `2` | Shape mode |
| `3` | Stamp mode |
| `4` | Erase mode |

---

## ğŸ”· Shape Mode â€” Step by Step

1. Click the **ğŸ”· Shapes** tab and select a shape (e.g. Star 5pt)
2. Configure **Fill color**, **Stroke color**, and **Opacity**
3. Show **two open hands** to the camera â€” the shape preview tracks your hand position
4. When you're happy with the placement, close **both hands into fists** simultaneously
5. Hold for **1.5 seconds** â€” the animated ring fills up â†’ shape locks to canvas ğŸ”’

---

## â• Adding Custom Gestures

1. Hold any hand pose you want to teach
2. Click **â• GESTURE** in the toolbar
3. Name your gesture, assign an emoji, and choose its action
4. Your gesture is saved in `localStorage` and appears in the **Gesture Guide** panel

---

## ğŸ—ï¸ Architecture

```
CV_GESTURE_SYSTEM.ipynb
â”‚
â”œâ”€â”€ Cell 1  â”€â”€â”€ Sanity check (no installs needed)
â”‚
â””â”€â”€ Cell 2  â”€â”€â”€ Main app
    â”‚
    â”œâ”€â”€ Python layer
    â”‚   â”œâ”€â”€ http.server.HTTPServer  (serves APP_HTML on port 8765)
    â”‚   â”œâ”€â”€ threading.Thread        (non-blocking background server)
    â”‚   â””â”€â”€ google.colab.output.eval_js  (tunnel URL retrieval)
    â”‚
    â””â”€â”€ Browser layer (single HTML string)
        â”œâ”€â”€ <video>   â€” raw webcam feed (hidden)
        â”œâ”€â”€ #camCanvas  â€” mirrored video frame render
        â”œâ”€â”€ #drawCanvas â€” persistent freehand strokes
        â”œâ”€â”€ #shapeCanvas â€” live shape ghost preview
        â”œâ”€â”€ #uiCanvas â€” landmarks, cursor, HUD overlays
        â”‚
        â”œâ”€â”€ MediaPipe Hands  (CDN, runs on device GPU/CPU)
        â”‚   â””â”€â”€ 21 3D landmarks â†’ classifyGesture()
        â”‚
        â”œâ”€â”€ Gesture Engine
        â”‚   â”œâ”€â”€ isFist()         â€” finger-curl detection
        â”‚   â”œâ”€â”€ classifyGesture() â€” rule-based pose matching
        â”‚   â””â”€â”€ customGestures   â€” user-defined landmark snapshots
        â”‚
        â”œâ”€â”€ Drawing Engine
        â”‚   â”œâ”€â”€ Catmull-Rom smoothing (SMOOTH_N = 3)
        â”‚   â”œâ”€â”€ Brush styles: round / square / glow / neon
        â”‚   â”œâ”€â”€ Undo stack (MAX_UNDO = 20, ImageData snapshots)
        â”‚   â””â”€â”€ Stamp renderer (emoji on 2D canvas)
        â”‚
        â””â”€â”€ Shape Engine
            â”œâ”€â”€ 13 shape renderers (arc, path, polygon helpers)
            â”œâ”€â”€ Two-hand scale detection (Peace gesture)
            â”œâ”€â”€ Both-fists lock countdown (SVG ring animation)
            â””â”€â”€ lockedShapes[] â†’ merged into drawCanvas on commit
```

---

## ğŸ“¦ Tech Stack

| Layer | Technology |
|---|---|
| Hand tracking | [MediaPipe Hands](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker) via CDN |
| Rendering | HTML5 Canvas API (4 stacked layers) |
| Server | Python `http.server` + `threading` |
| Colab bridge | `google.colab.output.eval_js` |
| Fonts | Rajdhani + Share Tech Mono (Google Fonts) |
| Dependencies | **None** (everything loaded from CDN at runtime) |

---

## ğŸ’¡ Tips for Best Results

- **Lighting:** Use a well-lit environment â€” natural or front-facing light works best
- **Background:** Plain, uncluttered backgrounds improve landmark detection accuracy
- **Distance:** Keep your hand 40â€“70 cm from the camera
- **Speed:** Slow, deliberate gestures reduce false positives
- **Both-Fist Lock:** Make sure both hands are fully visible before clenching

---

## ğŸ—ºï¸ Roadmap

- [ ] Voice command integration alongside gesture control
- [ ] Multi-layer canvas with individual layer management
- [ ] Text tool â€” spell words letter-by-letter in the air
- [ ] WebSocket mode for collaborative multi-user canvas
- [ ] Gesture macro recording and playback
- [ ] Export as SVG (vector paths from landmark trajectories)
- [ ] Standalone web app (no Colab dependency)

---

## ğŸ“„ License

MIT Â© â€” free to use, fork, and build upon.

---

<div align="center">

**Built with MediaPipe Â· Python Â· Vanilla JS Â· â˜•**

*If this project helped you, consider giving it a â­*

</div>
